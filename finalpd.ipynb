{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f8a6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, kurtosis, skew\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8188c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# 1) System Parameters\n",
    "# ---------------------\n",
    "SNR_dB = np.arange(-25, 6, 1)  # SNR range in dB\n",
    "SNR_linear = 10 ** (SNR_dB / 10)\n",
    "\n",
    "# Channel gains\n",
    "h_u1_2 = 0.65\n",
    "h_u2_2 = 2.7\n",
    "h_oma_2 = 0.45\n",
    "\n",
    "# Power allocation\n",
    "alpha1 = 0.8\n",
    "alpha2 = 0.2\n",
    "\n",
    "# Detection parameters\n",
    "Ns = 50\n",
    "sigma_n2 = 1.0\n",
    "alpha_cyclic = 0.1 # Dekho \n",
    "Pf_u1 = Pf_u2 = Pf_oma = 0.10\n",
    "M1, M2 = 2, 2\n",
    "\n",
    "# Monte Carlo parameters\n",
    "num_samples = 10000\n",
    "\n",
    "# Machine learning parameters\n",
    "test_size = 0.2\n",
    "\n",
    "# Cyclic lags for CAF\n",
    "cyclic_lags = [18, 15]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac9ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 2) Cyclic Correlation Detection Functions\n",
    "# -------------------------------------------------\n",
    "def compute_cyclic_threshold(Pf, Ns, sigma_n2):\n",
    "    return np.sqrt(2 * sigma_n2 / Ns) * norm.ppf(1 - Pf)\n",
    "\n",
    "def cyclic_correlation_pd(SNR, alpha, h_2, Ns, lambda_val, sigma_n2, alpha_cyclic):\n",
    "    signal_power = alpha * h_2 * SNR\n",
    "    var_cyclic_H1 = (sigma_n2 + signal_power)**2 / Ns\n",
    "    return 1 - norm.cdf((lambda_val - signal_power) / np.sqrt(var_cyclic_H1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e845cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 3) ML Classifiers Setup\n",
    "# -------------------------------------------------\n",
    "def extract_features(received_signal):\n",
    "    mag = np.abs(received_signal)\n",
    "    \n",
    "    # CAF features\n",
    "    caf_values = []\n",
    "    for lag in cyclic_lags:\n",
    "        if lag < Ns:\n",
    "            caf = np.mean(received_signal[:-lag] * np.conj(received_signal[lag:]))\n",
    "            caf_values.append(np.abs(caf))\n",
    "    caf_peak = max(caf_values) if caf_values else 0.0\n",
    "    caf_variance = np.var(caf_values) if len(caf_values) > 1 else 0.0\n",
    "    \n",
    "    # Signal power estimate\n",
    "    signal_power = max(np.mean(mag ** 2) - sigma_n2, 0)\n",
    "    \n",
    "    # Statistical features\n",
    "    mag_kurtosis = kurtosis(mag)\n",
    "    mag_skewness = skew(mag)\n",
    "    \n",
    "    return [\n",
    "        np.mean(mag),\n",
    "        np.std(mag),\n",
    "        np.sum(mag ** 2),\n",
    "        np.percentile(mag, 25),\n",
    "        np.percentile(mag, 75),\n",
    "        caf_peak,\n",
    "        caf_variance,\n",
    "        signal_power,\n",
    "        mag_kurtosis,\n",
    "        mag_skewness,\n",
    "    ]\n",
    "\n",
    "def generate_ml_data(snr_lin, num_samples):\n",
    "    X, y = [], []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        signal_present = np.random.rand() > 0.5\n",
    "\n",
    "        if signal_present:\n",
    "            x_u1 = np.sqrt(alpha1 * h_u1_2 * snr_lin) * np.random.randn(Ns)\n",
    "            x_u2 = np.sqrt(alpha2 * h_u2_2 * snr_lin) * np.random.randn(Ns)\n",
    "            signal = x_u1 + x_u2\n",
    "        else:\n",
    "            signal = np.zeros(Ns)\n",
    "\n",
    "        noise = np.sqrt(sigma_n2 / 2) * (np.random.randn(Ns) + 1j * np.random.randn(Ns))\n",
    "        received = signal + noise\n",
    "\n",
    "        features = extract_features(received)\n",
    "        X.append(features)\n",
    "        y.append(signal_present)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def train_classifiers(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    classifiers = {\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "        'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'),\n",
    "        'SVM': SVC(probability=True, random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_probs = clf.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        results[name] = (fpr, tpr, roc_auc)\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe0602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR = -25 dB | U1-Pd = 0.036 | U2-Pd = 0.036 | OMA-Pd = 0.036\n",
      "ML Results: RF-Pd = 0.079, LR-Pd = 0.088, DT-Pd = 0.097, XGB-Pd = 0.095, SVM-Pd = 0.116\n",
      "\n",
      "SNR = -24 dB | U1-Pd = 0.036 | U2-Pd = 0.036 | OMA-Pd = 0.036\n",
      "ML Results: RF-Pd = 0.098, LR-Pd = 0.095, DT-Pd = 0.109, XGB-Pd = 0.134, SVM-Pd = 0.100\n",
      "\n",
      "SNR = -23 dB | U1-Pd = 0.037 | U2-Pd = 0.037 | OMA-Pd = 0.037\n",
      "ML Results: RF-Pd = 0.090, LR-Pd = 0.099, DT-Pd = 0.102, XGB-Pd = 0.110, SVM-Pd = 0.095\n",
      "\n",
      "SNR = -22 dB | U1-Pd = 0.037 | U2-Pd = 0.037 | OMA-Pd = 0.037\n",
      "ML Results: RF-Pd = 0.101, LR-Pd = 0.095, DT-Pd = 0.097, XGB-Pd = 0.101, SVM-Pd = 0.111\n",
      "\n",
      "SNR = -21 dB | U1-Pd = 0.038 | U2-Pd = 0.038 | OMA-Pd = 0.037\n",
      "ML Results: RF-Pd = 0.098, LR-Pd = 0.105, DT-Pd = 0.105, XGB-Pd = 0.096, SVM-Pd = 0.109\n",
      "\n",
      "SNR = -20 dB | U1-Pd = 0.039 | U2-Pd = 0.039 | OMA-Pd = 0.038\n",
      "ML Results: RF-Pd = 0.109, LR-Pd = 0.135, DT-Pd = 0.100, XGB-Pd = 0.121, SVM-Pd = 0.138\n",
      "\n",
      "SNR = -19 dB | U1-Pd = 0.040 | U2-Pd = 0.040 | OMA-Pd = 0.039\n",
      "ML Results: RF-Pd = 0.109, LR-Pd = 0.132, DT-Pd = 0.101, XGB-Pd = 0.096, SVM-Pd = 0.137\n",
      "\n",
      "SNR = -18 dB | U1-Pd = 0.041 | U2-Pd = 0.041 | OMA-Pd = 0.040\n",
      "ML Results: RF-Pd = 0.127, LR-Pd = 0.111, DT-Pd = 0.103, XGB-Pd = 0.112, SVM-Pd = 0.105\n",
      "\n",
      "SNR = -17 dB | U1-Pd = 0.043 | U2-Pd = 0.043 | OMA-Pd = 0.042\n",
      "ML Results: RF-Pd = 0.119, LR-Pd = 0.118, DT-Pd = 0.105, XGB-Pd = 0.106, SVM-Pd = 0.105\n",
      "\n",
      "SNR = -16 dB | U1-Pd = 0.045 | U2-Pd = 0.045 | OMA-Pd = 0.043\n",
      "ML Results: RF-Pd = 0.098, LR-Pd = 0.133, DT-Pd = 0.096, XGB-Pd = 0.108, SVM-Pd = 0.137\n",
      "\n",
      "SNR = -15 dB | U1-Pd = 0.048 | U2-Pd = 0.048 | OMA-Pd = 0.046\n",
      "ML Results: RF-Pd = 0.130, LR-Pd = 0.180, DT-Pd = 0.105, XGB-Pd = 0.128, SVM-Pd = 0.162\n",
      "\n",
      "SNR = -14 dB | U1-Pd = 0.051 | U2-Pd = 0.052 | OMA-Pd = 0.049\n",
      "ML Results: RF-Pd = 0.155, LR-Pd = 0.175, DT-Pd = 0.101, XGB-Pd = 0.147, SVM-Pd = 0.165\n",
      "\n",
      "SNR = -13 dB | U1-Pd = 0.056 | U2-Pd = 0.057 | OMA-Pd = 0.053\n",
      "ML Results: RF-Pd = 0.164, LR-Pd = 0.183, DT-Pd = 0.110, XGB-Pd = 0.140, SVM-Pd = 0.190\n",
      "\n",
      "SNR = -12 dB | U1-Pd = 0.063 | U2-Pd = 0.064 | OMA-Pd = 0.059\n",
      "ML Results: RF-Pd = 0.147, LR-Pd = 0.204, DT-Pd = 0.105, XGB-Pd = 0.153, SVM-Pd = 0.201\n",
      "\n",
      "SNR = -11 dB | U1-Pd = 0.072 | U2-Pd = 0.074 | OMA-Pd = 0.066\n",
      "ML Results: RF-Pd = 0.209, LR-Pd = 0.255, DT-Pd = 0.113, XGB-Pd = 0.194, SVM-Pd = 0.246\n",
      "\n",
      "SNR = -10 dB | U1-Pd = 0.085 | U2-Pd = 0.087 | OMA-Pd = 0.076\n",
      "ML Results: RF-Pd = 0.251, LR-Pd = 0.298, DT-Pd = 0.126, XGB-Pd = 0.241, SVM-Pd = 0.302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------------\n",
    "# 4) Main Simulation\n",
    "# -------------------------------------------------\n",
    "Pd_u1, Pd_u2, Pd_oma = [], [], []\n",
    "Pd_rf, Pd_lr, Pd_dt, Pd_xgb, Pd_svm = [], [], [], [], []\n",
    "\n",
    "for idx, snr_db in enumerate(SNR_dB):\n",
    "    snr_lin = SNR_linear[idx]\n",
    "\n",
    "    # Compute thresholds for cyclic correlation detection\n",
    "    lambda_noma = compute_cyclic_threshold(Pf_u1, Ns, sigma_n2)\n",
    "    lambda_oma = compute_cyclic_threshold(Pf_oma, Ns, sigma_n2)\n",
    "\n",
    "    pd_u1 = cyclic_correlation_pd(snr_lin, alpha1, h_u1_2, Ns, lambda_noma, sigma_n2, alpha_cyclic)\n",
    "    pd_u2 = cyclic_correlation_pd(snr_lin, alpha2, h_u2_2, Ns, lambda_noma, sigma_n2, alpha_cyclic)\n",
    "    pd_oma = cyclic_correlation_pd(snr_lin, 1.0, h_oma_2, Ns, lambda_oma, sigma_n2, alpha_cyclic)\n",
    "\n",
    "    X, y = generate_ml_data(snr_lin, num_samples)\n",
    "    results = train_classifiers(X, y)\n",
    "\n",
    "    fpr_desired = 0.10\n",
    "    pd_results = {}\n",
    "\n",
    "    for name, (fpr, tpr, _) in results.items():\n",
    "        if max(fpr) >= fpr_desired:\n",
    "            interp_tpr = interp1d(fpr, tpr)\n",
    "            pd_results[name] = float(interp_tpr(fpr_desired))\n",
    "        else:\n",
    "            pd_results[name] = 1.0\n",
    "\n",
    "    Pd_u1.append(pd_u1)\n",
    "    Pd_u2.append(pd_u2)\n",
    "    Pd_oma.append(pd_oma)\n",
    "    Pd_rf.append(pd_results.get('Random Forest', 0))\n",
    "    Pd_lr.append(pd_results.get('Logistic Regression', 0))\n",
    "    Pd_dt.append(pd_results.get('Decision Tree', 0))\n",
    "    Pd_xgb.append(pd_results.get('XGBoost', 0))\n",
    "    Pd_svm.append(pd_results.get('SVM', 0))\n",
    "\n",
    "    print(f\"SNR = {snr_db:3d} dB | U1-Pd = {pd_u1:.3f} | U2-Pd = {pd_u2:.3f} | OMA-Pd = {pd_oma:.3f}\")\n",
    "    print(f\"ML Results: RF-Pd = {pd_results['Random Forest']:.3f}, LR-Pd = {pd_results['Logistic Regression']:.3f}, DT-Pd = {pd_results['Decision Tree']:.3f}, XGB-Pd = {pd_results['XGBoost']:.3f}, SVM-Pd = {pd_results['SVM']:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c66617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------\n",
    "# 5) Plot Results\n",
    "# -------------------------------------------------\n",
    "window_length = 7  # Must be odd\n",
    "polyorder = 2\n",
    "\n",
    "def smooth(data):\n",
    "    return savgol_filter(data, window_length=window_length, polyorder=polyorder)\n",
    "\n",
    "Pd_u1_s = smooth(Pd_u1)\n",
    "Pd_u2_s = smooth(Pd_u2)\n",
    "Pd_oma_s = smooth(Pd_oma)\n",
    "Pd_rf_s = smooth(Pd_rf)\n",
    "Pd_lr_s = smooth(Pd_lr)\n",
    "Pd_dt_s = smooth(Pd_dt)\n",
    "Pd_xgb_s = smooth(Pd_xgb)\n",
    "Pd_svm_s = smooth(Pd_svm)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(SNR_dB, Pd_u1_s, 'b-o', label='U1-Pd (Cyclic)', markevery=2)\n",
    "plt.plot(SNR_dB, Pd_u2_s, 'r-s', label='U2-Pd (Cyclic)', markevery=2)\n",
    "plt.plot(SNR_dB, Pd_oma_s, 'g-^', label='OMA (Cyclic)', markevery=2)\n",
    "plt.plot(SNR_dB, Pd_rf_s, 'm-D', label='Random Forest', markevery=2, markersize=8)\n",
    "plt.plot(SNR_dB, Pd_lr_s, 'c-p', label='Logistic Regression', markevery=2, markersize=8)\n",
    "plt.plot(SNR_dB, Pd_dt_s, 'y-*', label='Decision Tree', markevery=2, markersize=10)\n",
    "plt.plot(SNR_dB, Pd_xgb_s, 'k-x', label='XGBoost', markevery=2, markersize=8)\n",
    "plt.plot(SNR_dB, Pd_svm_s, color='orange', marker='o', label='SVM', markevery=2, markersize=8)\n",
    "plt.plot(SNR_dB, [Pf_u1] * len(SNR_dB), 'b--', label='U1-Pf')\n",
    "plt.plot(SNR_dB, [Pf_u2] * len(SNR_dB), 'r--', label='U2-Pf')\n",
    "plt.xlabel('SNR (dB)', fontsize=12)\n",
    "plt.ylabel('Probability', fontsize=12)\n",
    "plt.title('Smoothed Detection Performance: Cyclic Correlation vs. ML Classifiers\\n($\\\\alpha_1 : \\\\alpha_2 = 4:1$)', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
