{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48240fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, kurtosis, skew\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d92b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------\n",
    "# 1) System Parameters\n",
    "# ---------------------\n",
    "SNR_dB = np.arange(-25, 6, 1)\n",
    "SNR_linear = 10**(SNR_dB / 10)\n",
    "h_u1_2, h_u2_2, h_oma_2 = 0.65, 2.7, 0.6\n",
    "alpha1, alpha2 = 0.8, 0.2\n",
    "Ns, sigma_n2, alpha_cyclic = 50, 1.0, 0.1\n",
    "Pf_u1 = Pf_u2 = Pf_oma = 0.10\n",
    "M1 = M2 = 2\n",
    "num_samples = 10000\n",
    "test_size = 0.2\n",
    "cyclic_lags = [18, 15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4047e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# 2) Cyclic Correlation Detection\n",
    "# ---------------------\n",
    "def compute_cyclic_threshold(Pf, Ns, sigma_n2):\n",
    "    return np.sqrt(2 * sigma_n2 / Ns) * norm.ppf(1 - Pf)\n",
    "\n",
    "def cyclic_correlation_pd(SNR, alpha, h_2, Ns, lambda_val, sigma_n2, alpha_cyclic):\n",
    "    signal_power = alpha * h_2 * SNR\n",
    "    var_cyclic_H1 = (sigma_n2 + signal_power)**2 / Ns\n",
    "    return 1 - norm.cdf((lambda_val - signal_power) / np.sqrt(var_cyclic_H1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef8e6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------\n",
    "# 3) ML Classifiers\n",
    "# ---------------------\n",
    "def generate_ml_data(snr_lin, num_samples):\n",
    "    X, y = [], []\n",
    "    for _ in range(num_samples):\n",
    "        signal_present = np.random.rand() > 0.5\n",
    "        if signal_present:\n",
    "            x_u1 = np.sqrt(alpha1 * h_u1_2 * snr_lin) * np.random.randn(Ns)\n",
    "            x_u2 = np.sqrt(alpha2 * h_u2_2 * snr_lin) * np.random.randn(Ns)\n",
    "            signal = x_u1 + x_u2\n",
    "        else:\n",
    "            signal = np.zeros(Ns)\n",
    "        noise = np.sqrt(sigma_n2 / 2) * (np.random.randn(Ns) + 1j * np.random.randn(Ns))\n",
    "        received = signal + noise\n",
    "        mag = np.abs(received)\n",
    "        \n",
    "        # CAF features\n",
    "        caf_values = []\n",
    "        for lag in cyclic_lags:\n",
    "            if lag < Ns:\n",
    "                caf = np.mean(received[:-lag] * np.conj(received[lag:]))\n",
    "                caf_values.append(np.abs(caf))\n",
    "        caf_peak = max(caf_values) if caf_values else 0.0\n",
    "        caf_variance = np.var(caf_values) if len(caf_values) > 1 else 0.0\n",
    "        \n",
    "        # Signal power\n",
    "        signal_power = max(np.mean(mag ** 2) - sigma_n2, 0)\n",
    "        \n",
    "        # Statistical features\n",
    "        mag_kurtosis = kurtosis(mag)\n",
    "        mag_skewness = skew(mag)\n",
    "        \n",
    "        features = [\n",
    "            np.mean(mag), np.std(mag), np.sum(mag**2),\n",
    "            np.percentile(mag, 25), np.percentile(mag, 75),\n",
    "            caf_peak, caf_variance, signal_power,\n",
    "            mag_kurtosis, mag_skewness\n",
    "        ]\n",
    "        X.append(features)\n",
    "        y.append(signal_present)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def train_classifiers(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    classifiers = {\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "        'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'),\n",
    "        'SVM': SVC(probability=True, random_state=42)\n",
    "    }\n",
    "    results = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_probs = clf.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        results[name] = (fpr, tpr, roc_auc)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42c419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------\n",
    "# 4) Throughput Calculation\n",
    "# ---------------------\n",
    "def calc_noma_rate_user(alpha, h_2, snr, interference_alpha, interference_h_2):\n",
    "    numerator = alpha * h_2 * snr\n",
    "    denominator = (interference_alpha * interference_h_2 * snr + sigma_n2)\n",
    "    return np.log2(1 + numerator / denominator)\n",
    "\n",
    "def calc_oma_rate(h_oma_2, snr):\n",
    "    return 0.5 * np.log2(1 + (h_oma_2 * snr) / sigma_n2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5215bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------\n",
    "# 5) Simulation Loop\n",
    "# ---------------------\n",
    "results_dict = {\n",
    "    'Pd_u1': [], 'Pd_u2': [], 'Pd_oma': [],\n",
    "    'Pd_rf': [], 'Pd_lr': [], 'Pd_dt': [], 'Pd_xgb': [], 'Pd_svm': [],\n",
    "    'th_noma_u1': [], 'th_noma_u2': [], 'th_noma_total': [],\n",
    "    'th_oma': [], 'th_noma_rf': [], 'th_noma_lr': [], 'th_noma_dt': [],\n",
    "    'th_noma_xgb': [], 'th_noma_svm': []\n",
    "}\n",
    "\n",
    "for snr_db, snr_lin in zip(SNR_dB, SNR_linear):\n",
    "    lambda_noma = compute_cyclic_threshold(Pf_u1, Ns, sigma_n2)\n",
    "    lambda_oma = compute_cyclic_threshold(Pf_oma, Ns, sigma_n2)\n",
    "\n",
    "    pd_u1 = cyclic_correlation_pd(snr_lin, alpha1, h_u1_2, Ns, lambda_noma, sigma_n2, alpha_cyclic)\n",
    "    pd_u2 = cyclic_correlation_pd(snr_lin, alpha2, h_u2_2, Ns, lambda_noma, sigma_n2, alpha_cyclic)\n",
    "    pd_oma = cyclic_correlation_pd(snr_lin, 1.0, h_oma_2, Ns, lambda_oma, sigma_n2, alpha_cyclic)\n",
    "\n",
    "    X, y = generate_ml_data(snr_lin, num_samples)\n",
    "    results = train_classifiers(X, y)\n",
    "    fpr_target = 0.10\n",
    "    pd_results = {\n",
    "        name: float(interp1d(fpr, tpr)(fpr_target)) if max(fpr) >= fpr_target else 1.0\n",
    "        for name, (fpr, tpr, _) in results.items()\n",
    "    }\n",
    "\n",
    "    rate_u1 = calc_noma_rate_user(alpha1, h_u1_2, snr_lin, alpha2, h_u2_2)\n",
    "    rate_u2 = calc_noma_rate_user(alpha2, h_u2_2, snr_lin, 0, 0)\n",
    "    rate_oma = calc_oma_rate(h_oma_2, snr_lin)\n",
    "\n",
    "    results_dict['Pd_u1'].append(pd_u1)\n",
    "    results_dict['Pd_u2'].append(pd_u2)\n",
    "    results_dict['Pd_oma'].append(pd_oma)\n",
    "    results_dict['Pd_rf'].append(pd_results['Random Forest'])\n",
    "    results_dict['Pd_lr'].append(pd_results['Logistic Regression'])\n",
    "    results_dict['Pd_dt'].append(pd_results['Decision Tree'])\n",
    "    results_dict['Pd_xgb'].append(pd_results['XGBoost'])\n",
    "    results_dict['Pd_svm'].append(pd_results['SVM'])\n",
    "\n",
    "    results_dict['th_noma_u1'].append(pd_u1 * rate_u1)\n",
    "    results_dict['th_noma_u2'].append(pd_u2 * rate_u2)\n",
    "    results_dict['th_noma_total'].append(pd_u1 * rate_u1 + pd_u2 * rate_u2)\n",
    "    results_dict['th_oma'].append(pd_oma * rate_oma)\n",
    "    results_dict['th_noma_rf'].append(pd_results['Random Forest'] * (rate_u1 + rate_u2))\n",
    "    results_dict['th_noma_lr'].append(pd_results['Logistic Regression'] * (rate_u1 + rate_u2))\n",
    "    results_dict['th_noma_dt'].append(pd_results['Decision Tree'] * (rate_u1 + rate_u2))\n",
    "    results_dict['th_noma_xgb'].append(pd_results['XGBoost'] * (rate_u1 + rate_u2))\n",
    "    results_dict['th_noma_svm'].append(pd_results['SVM'] * (rate_u1 + rate_u2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5febb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------\n",
    "# 6) Smooth and Plot\n",
    "# ---------------------\n",
    "window_length, polyorder = 7, 2\n",
    "smoothed_curves = {\n",
    "    key: savgol_filter(results_dict[key], window_length, polyorder)\n",
    "    for key in results_dict if key.startswith('th_')\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(SNR_dB, smoothed_curves['th_noma_total'], 'b-d', label='NOMA Total (Cyclic)', markevery=2)\n",
    "plt.plot(SNR_dB, smoothed_curves['th_noma_u1'], 'g--s', label='NOMA-U1 (Cyclic)', markevery=2)\n",
    "plt.plot(SNR_dB, smoothed_curves['th_noma_u2'], 'y--s', label='NOMA-U2 (Cyclic)', markevery=2)\n",
    "plt.plot(SNR_dB, smoothed_curves['th_oma'], 'r-^', label='OMA (Cyclic)', markevery=2)\n",
    "\n",
    "# FIX: Use `color=` for named colors\n",
    "plt.plot(SNR_dB, smoothed_curves['th_noma_rf'], 'm-D', label='NOMA (Random Forest)', markevery=2)\n",
    "plt.plot(SNR_dB, smoothed_curves['th_noma_lr'], 'c-p', label='NOMA (Logistic Regression)', markevery=2)\n",
    "plt.plot(SNR_dB, smoothed_curves['th_noma_dt'], 'k-*', label='NOMA (Decision Tree)', markevery=2)\n",
    "plt.plot(SNR_dB, smoothed_curves['th_noma_xgb'], marker='x', linestyle='-', color='orange', label='NOMA (XGBoost)', markevery=2)\n",
    "plt.plot(SNR_dB, smoothed_curves['th_noma_svm'], marker='v', linestyle='-', color='purple', label='NOMA (SVM)', markevery=2)\n",
    "\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Effective Throughput (bps/Hz)')\n",
    "plt.title('Throughput Performance: NOMA vs OMA with Cyclic and ML Detection (Smoothed)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('noma_oma_ml_throughput_comparison_smooth.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d7bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------\n",
    "# 7) Print 0 dB Analysis\n",
    "# ---------------------\n",
    "idx_0dB = np.where(SNR_dB == 0)[0][0]\n",
    "print(\"\\nThroughput at SNR = 0 dB (Original Data):\")\n",
    "print(f\"NOMA U1 (Cyclic): {results_dict['th_noma_u1'][idx_0dB]:.4f} bps/Hz\")\n",
    "print(f\"NOMA U2 (Cyclic): {results_dict['th_noma_u2'][idx_0dB]:.4f} bps/Hz\")\n",
    "print(f\"NOMA Total (Cyclic): {results_dict['th_noma_total'][idx_0dB]:.4f} bps/Hz\")\n",
    "print(f\"OMA (Cyclic): {results_dict['th_oma'][idx_0dB]:.4f} bps/Hz\")\n",
    "print(f\"NOMA (Random Forest): {results_dict['th_noma_rf'][idx_0dB]:.4f} bps/Hz\")\n",
    "print(f\"NOMA (Logistic Regression): {results_dict['th_noma_lr'][idx_0dB]:.4f} bps/Hz\")\n",
    "print(f\"NOMA (Decision Tree): {results_dict['th_noma_dt'][idx_0dB]:.4f} bps/Hz\")\n",
    "print(f\"NOMA (XGBoost): {results_dict['th_noma_xgb'][idx_0dB]:.4f} bps/Hz\")\n",
    "print(f\"NOMA (SVM): {results_dict['th_noma_svm'][idx_0dB]:.4f} bps/Hz\")\n",
    "print(f\"NOMA Total (Cyclic)/OMA Ratio: {results_dict['th_noma_total'][idx_0dB] / results_dict['th_oma'][idx_0dB]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
